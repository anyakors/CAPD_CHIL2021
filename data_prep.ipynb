{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Bio import SeqIO\n",
    "import numpy as np\n",
    "from utils import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ENST00000257818.2' 'ENST00000241453.11' 'ENST00000216336.2'\n",
      " 'ENST00000284509.10' 'ENST00000592205.5' 'ENST00000633060.1'\n",
      " 'ENST00000427103.5' 'ENST00000360121.4' 'ENST00000378962.3'\n",
      " 'ENST00000612677.4' 'ENST00000309017.7' 'ENST00000304625.2'\n",
      " 'ENST00000380987.2' 'ENST00000598473.1' 'ENST00000233997.3'\n",
      " 'ENST00000620695.2' 'ENST00000367279.8' 'ENST00000376581.9'\n",
      " 'ENST00000635923.1' 'ENST00000448387.6' 'ENST00000537784.5'\n",
      " 'ENST00000563039.2' 'ENST00000381297.9' 'ENST00000611771.1'\n",
      " 'ENST00000430686.2' 'ENST00000304639.3' 'ENST00000393118.6'\n",
      " 'ENST00000554578.5' 'ENST00000400007.8' 'ENST00000245479.2'\n",
      " 'ENST00000561385.5' 'ENST00000215855.6' 'ENST00000293373.10'\n",
      " 'ENST00000468385.1' 'ENST00000477988.1' 'ENST00000282026.1'\n",
      " 'ENST00000346128.10' 'ENST00000261233.8' 'ENST00000359135.7'\n",
      " 'ENST00000367814.8' 'ENST00000515859.5' 'ENST00000507316.1'\n",
      " 'ENST00000355530.6' 'ENST00000531348.5' 'ENST00000262262.4'\n",
      " 'ENST00000264824.4' 'ENST00000527615.5' 'ENST00000381501.7'\n",
      " 'ENST00000373304.3' 'ENST00000281938.6']\n"
     ]
    }
   ],
   "source": [
    "transcript_file = np.genfromtxt('./data/GENCODE_v34_hg38_comprehensive', usecols=(1, 2, 3, 4, 5, 9, 10), skip_header=1, dtype='str')\n",
    "DE_tr = np.genfromtxt('./lists/limma_DE_AML_RAN', usecols=(1,), skip_header=1, dtype='str')\n",
    "\n",
    "print(DE_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "fasta_seq = SeqIO.parse(open('./data/hg38.fa'), 'fasta')\n",
    "\n",
    "for fasta in fasta_seq:\n",
    "    name, sequence = fasta.id, str(fasta.seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "transcripts = []\n",
    "labels = []\n",
    "\n",
    "# flanking ends on each side are of this length to include some context\n",
    "context = 1000\n",
    "\n",
    "for row in transcript_file:\n",
    "    # explicitly checking transcript_name\n",
    "    if row[0] in DE_tr:\n",
    "        # sequence from start to end\n",
    "        s = sequence[int(row[3]) - context: int(row[4]) + context].upper()\n",
    "        # adding the transcripts of the sense strand: whole transcript + flanks + zero-padded, labels + zero-padded\n",
    "        if row[2] == '+':\n",
    "            # extract the transcript sequence with 1k flanks\n",
    "            if 'N' not in s:\n",
    "                # padding labels here\n",
    "                pad = 5000 - (len(s) - context * 2) % 5000\n",
    "                es, ee = row[5].split(',')[:-1], row[6].split(',')[:-1]\n",
    "                # decrease the pad length from both sides because the context-1 and context+sequence+1 sites are\n",
    "                # donor and acceptor, respectively\n",
    "                y = make_labels(s, context, es, ee)\n",
    "                labels.append(y)\n",
    "                # padding sequence with Os\n",
    "                s = (pad // 2) * 'O' + s + (pad - pad // 2) * 'O'\n",
    "                transcripts.append(s)\n",
    "            else:\n",
    "                print('contains N')\n",
    "        # adding the transcripts of the antisense strand\n",
    "        if row[2] == '-':\n",
    "            if 'N' not in s:\n",
    "                # padding labels here\n",
    "                pad = 5000 - (len(s) - context * 2) % 5000\n",
    "                # decrease the pad length from both sides because the context-1 and context+sequence+1 sites are\n",
    "                # donor and acceptor, respectively\n",
    "                es, ee = row[5].split(',')[:-1], row[6].split(',')[:-1]\n",
    "                # decrease the pad length from both sides because the context-1 and context+sequence+1 sites are\n",
    "                # donor and acceptor, respectively\n",
    "                y = make_labels(s, context, es, ee)\n",
    "                labels.append(y)\n",
    "                # hot-encoding labels and adding hot-encoded labels to a new list\n",
    "                # getting complementary seq\n",
    "                s = ''.join([complementary(x) for x in s])\n",
    "                # padding sequence with Os\n",
    "                s = (pad // 2) * 'O' + s + (pad - pad // 2) * 'O'\n",
    "                transcripts.append(s)\n",
    "            else:\n",
    "                print('contains N')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 2, 21, 11, 23]\n",
      "[248956422 242193529 198295559 190214555 181538259 170805979 159345973\n",
      " 145138636 138394717 133797422 135086622 133275309 114364328 107043718\n",
      " 101991189  90338345  83257441  80373285  58617616  64444167  46709983\n",
      "  50818468 156040895  57227415]\n",
      "1808681051\n"
     ]
    }
   ],
   "source": [
    "def chr_to_N(s):\n",
    "    if s[3:]=='X':\n",
    "        N = 22\n",
    "    elif s[3:]=='Y':\n",
    "        N = 23\n",
    "    else:\n",
    "        N = int(s[3:]) - 1\n",
    "        \n",
    "    return N\n",
    "        \n",
    "a = ['chr1', 'chr3', 'chr22', 'chr12', 'chrY']\n",
    "print([chr_to_N(x) for x in a])\n",
    "\n",
    "chr_len = np.genfromtxt('./data/chr_len_hg38.txt', usecols=(0,), dtype='int')\n",
    "print(chr_len)\n",
    "print(np.sum(chr_len[:10]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37240\n"
     ]
    }
   ],
   "source": [
    "print(len(sequence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ENST00000257818.3\n",
      "33858575 33892076\n",
      "chr11\n",
      "1842538626 1842540626\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for t in DE_tr[0:1]:\n",
    "    found = 0\n",
    "    # explicitly checking transcript_name\n",
    "    for row in transcript_file:\n",
    "        if row[0][:15]==t[:15]:\n",
    "            found = 1\n",
    "            print(row[0])\n",
    "            print(row[3], row[4])\n",
    "            print(row[1])\n",
    "            chrN = chr_to_N(row[1])\n",
    "            start = np.sum(chr_len[:chrN])\n",
    "            s = sequence[int(row[3]) + start - context: int(row[4]) + start + context].upper()\n",
    "            print(int(row[3]) + start - context, int(row[3]) + start + context)\n",
    "            print(s)\n",
    "            # adding the transcripts of the sense strand: whole transcript + flanks + zero-padded, labels + zero-padded\n",
    "            if row[2] == '+':\n",
    "                # extract the transcript sequence with 1k flanks\n",
    "                if 'N' not in s:\n",
    "                    # padding labels here\n",
    "                    pad = 5000 - (len(s) - context * 2) % 5000\n",
    "                    es, ee = row[5].split(',')[:-1], row[6].split(',')[:-1]\n",
    "                    # decrease the pad length from both sides because the context-1 and context+sequence+1 sites are\n",
    "                    # donor and acceptor, respectively\n",
    "                    y = make_labels(s, context, es, ee)\n",
    "                    labels.append(y)\n",
    "                    # padding sequence with Os\n",
    "                    s = (pad // 2) * 'O' + s + (pad - pad // 2) * 'O'\n",
    "                    transcripts.append(s)\n",
    "                else:\n",
    "                    print('contains N')\n",
    "            # adding the transcripts of the antisense strand\n",
    "            if row[2] == '-':\n",
    "                if 'N' not in s:\n",
    "                    # padding labels here\n",
    "                    pad = 5000 - (len(s) - context * 2) % 5000\n",
    "                    # decrease the pad length from both sides because the context-1 and context+sequence+1 sites are\n",
    "                    # donor and acceptor, respectively\n",
    "                    es, ee = row[5].split(',')[:-1], row[6].split(',')[:-1]\n",
    "                    # decrease the pad length from both sides because the context-1 and context+sequence+1 sites are\n",
    "                    # donor and acceptor, respectively\n",
    "                    y = make_labels(s, context, es, ee)\n",
    "                    labels.append(y)\n",
    "                    # hot-encoding labels and adding hot-encoded labels to a new list\n",
    "                    # getting complementary seq\n",
    "                    s = ''.join([complementary(x) for x in s])\n",
    "                    # padding sequence with Os\n",
    "                    s = (pad // 2) * 'O' + s + (pad - pad // 2) * 'O'\n",
    "                    transcripts.append(s)\n",
    "                else:\n",
    "                    print('contains N')\n",
    "    if found==0:\n",
    "        print(t, 'not found')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "50\n",
      "ENST00000371007\n",
      "yeth\n",
      "True\n",
      "True\n",
      "True\n",
      "OOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOO\n"
     ]
    }
   ],
   "source": [
    "print(len(transcripts))\n",
    "print(len(DE_tr))\n",
    "\n",
    "print(transcript_file[0][0][:15])\n",
    "if 'ENST00000281938.6' in DE_tr:\n",
    "    print('yeth')\n",
    "    \n",
    "print(transcripts[0]==transcripts[1])\n",
    "print(transcripts[1]==transcripts[2])\n",
    "print(transcripts[45]==transcripts[46])\n",
    "\n",
    "print(transcripts[45])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
